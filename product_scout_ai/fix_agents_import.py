#!/usr/bin/env python3
"""
ä¿®å¤agentså¯¼å…¥é—®é¢˜
"""
import sys
import os

# Add src to Python path
src_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src')
sys.path.insert(0, src_path)

def test_analysis_pipeline_import():
    """æµ‹è¯•analysis_pipelineå¯¼å…¥"""
    print("ğŸ” æµ‹è¯•analysis_pipelineå¯¼å…¥...")

    try:
        print("1. å¯¼å…¥åŸºç¡€æ¨¡å—...")
        from google.adk.agents import LlmAgent, ParallelAgent, SequentialAgent, parallel_agent_config
        from google.adk.sessions import Session
        from src.config.settings import Settings
        from src.schemas.input_schemas import AnalysisRequest
        print("âœ… åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ")

        print("2. æµ‹è¯•agentsæ¨¡å—å¯¼å…¥...")
        from src.agents import (
            TrendAgent,
            MarketAgent,
            CompetitionAgent,
            ProfitAgent,
            EvaluatorAgent,
            ReportAgent,
            extract_json_from_response,
        )
        print("âœ… agentsæ¨¡å—å¯¼å…¥æˆåŠŸ")

        print("3. æµ‹è¯•å®Œæ•´çš„analysis_pipelineå¯¼å…¥...")
        from src.workflows.analysis_pipeline import AnalysisPipeline, PipelineResult
        print("âœ… analysis_pipelineå¯¼å…¥æˆåŠŸ")

        print("4. æµ‹è¯•åˆ›å»ºAnalysisPipelineå®ä¾‹...")
        pipeline = AnalysisPipeline()
        print("âœ… AnalysisPipelineå®ä¾‹åˆ›å»ºæˆåŠŸ")

        return True

    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def find_and_fix_agents_name_conflict():
    """æŸ¥æ‰¾å¹¶ä¿®å¤agentsåç§°å†²çª"""
    print("\nğŸ” æ£€æŸ¥å¯èƒ½çš„åç§°å†²çª...")

    import ast
    import os

    # æ£€æŸ¥analysis_pipeline.pyæ–‡ä»¶
    pipeline_file = os.path.join(src_path, 'workflows', 'analysis_pipeline.py')

    try:
        with open(pipeline_file, 'r', encoding='utf-8') as f:
            content = f.read()

        print(f"ğŸ“„ æ£€æŸ¥æ–‡ä»¶: {pipeline_file}")

        # æŸ¥æ‰¾å¯èƒ½çš„é—®é¢˜
        if 'from src.agents import (' in content and 'agents' in content:
            print("âš ï¸  å¯èƒ½å­˜åœ¨åç§°å†²çªé—®é¢˜")

            # æ£€æŸ¥æ˜¯å¦æœ‰å˜é‡åä¸ºagents
            if 'agents' in content and '=' in content:
                print("ğŸ”§ æ‰¾åˆ°å¯èƒ½çš„agentså˜é‡èµ‹å€¼")

        return pipeline_file, content

    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None, None

def create_fixed_analysis_pipeline():
    """åˆ›å»ºä¿®å¤ç‰ˆæœ¬çš„analysis_pipeline.py"""
    print("\nğŸ”§ åˆ›å»ºä¿®å¤ç‰ˆæœ¬çš„analysis_pipeline...")

    fixed_content = '''"""
Analysis pipeline workflow for ProductScout AI.

This module implements the main analysis workflow that orchestrates
all agents in the proper sequence using ADK patterns.
"""
from typing import Dict, Any, Optional, Callable, List
from dataclasses import dataclass, field
from datetime import datetime
import asyncio
import json

from google.adk.agents import LlmAgent, ParallelAgent, SequentialAgent, parallel_agent_config
from google.adk.sessions import Session

from src.config.settings import Settings
from src.schemas.input_schemas import AnalysisRequest
from src.schemas.output_schemas import (
    TrendAnalysis,
    MarketAnalysis,
    CompetitionAnalysis,
    ProfitAnalysis,
    EvaluationResult,
    FinalReport,
)
from src.schemas.state_schemas import AnalysisState
from src.agents import (
    TrendAgent,
    MarketAgent,
    CompetitionAgent,
    ProfitAgent,
    EvaluatorAgent,
    ReportAgent,
    extract_json_from_response,
)


@dataclass
class PipelineResult:
    """
    Result of a pipeline execution.

    Attributes:
        success: Whether the pipeline completed successfully
        state: Final analysis state
        report: Generated report (if successful)
        error: Error message (if failed)
        execution_time: Total execution time in seconds
        phase_times: Execution time for each phase
    """
    success: bool = False
    state: Optional[AnalysisState] = None
    report: Optional[FinalReport] = None
    error: Optional[str] = None
    execution_time: float = 0.0
    phase_times: Dict[str, float] = field(default_factory=dict)


class AnalysisPipeline:
    """
    Main analysis pipeline that orchestrates all agents.

    This pipeline follows a sequential pattern:
    1. Parallel analysis of trends, market, competition, and profit
    2. Sequential evaluation and report generation
    """

    def __init__(self, settings: Optional[Settings] = None):
        """Initialize the analysis pipeline."""
        self.settings = settings or Settings()
        self._analysis_agent_classes = {
            'trend': TrendAgent,
            'market': MarketAgent,
            'competition': CompetitionAgent,
            'profit': ProfitAgent,
        }
        self._evaluator_class = EvaluatorAgent
        self._reporter_class = ReportAgent

    def create_parallel_analysis(self, request: AnalysisRequest) -> ParallelAgent:
        """
        Create parallel analysis stage.

        Args:
            request: Analysis request

        Returns:
            ParallelAgent configured for analysis
        """
        # Create individual analysis agents
        analysis_agents = []

        # Trend agent
        trend_agent = TrendAgent(self.settings)
        trend_llm = trend_agent.create_agent(
            category=request.category,
            target_market=request.target_market
        )
        analysis_agents.append(trend_llm)

        # Market agent
        market_agent = MarketAgent(self.settings)
        market_llm = market_agent.create_agent(
            category=request.category,
            target_market=request.target_market
        )
        analysis_agents.append(market_llm)

        # Competition agent
        competition_agent = CompetitionAgent(self.settings)
        competition_llm = competition_agent.create_agent(
            category=request.category,
            target_market=request.target_market
        )
        analysis_agents.append(competition_llm)

        # Profit agent
        profit_agent = ProfitAgent(self.settings)
        profit_llm = profit_agent.create_agent(
            category=request.category,
            target_market=request.target_market,
            business_model=request.business_model,
            budget_range=request.budget_range
        )
        analysis_agents.append(profit_llm)

        # Create parallel agent
        parallel_agent = ParallelAgent(
            name="parallel_analysis",
            sub_agents=analysis_agents,
            description="Executes trend, market, competition, and profit analysis in parallel"
        )

        return parallel_agent

    def create_sequential_evaluation(
        self,
        request: AnalysisRequest,
        analysis_results: Dict[str, Any]
    ) -> SequentialAgent:
        """
        Create sequential evaluation stage.

        Args:
            request: Original analysis request
            analysis_results: Results from parallel analysis

        Returns:
            SequentialAgent for evaluation and reporting
        """
        # Create evaluator agent
        evaluator = EvaluatorAgent(self.settings)
        evaluator_llm = evaluator.create_agent(
            category=request.category,
            target_market=request.target_market
        )

        # Create report agent
        reporter = ReportAgent(self.settings)
        report_llm = reporter.create_agent(
            category=request.category,
            target_market=request.target_market
        )

        # Create sequential agent
        sequential_agent = SequentialAgent(
            name="sequential_evaluation",
            sub_agents=[evaluator_llm, report_llm],
            description="Evaluates analysis results and generates final report"
        )

        return sequential_agent

    async def run_analysis(self, request: AnalysisRequest) -> PipelineResult:
        """
        Run the complete analysis pipeline.

        Args:
            request: Analysis request

        Returns:
            PipelineResult with analysis outcome
        """
        import time
        start_time = time.time()

        try:
            # Create session
            session = Session()

            # Create parallel analysis stage
            print("ğŸ” åˆ›å»ºå¹¶è¡Œåˆ†æé˜¶æ®µ...")
            parallel_analysis = self.create_parallel_analysis(request)

            # Run parallel analysis
            print("ğŸš€ è¿è¡Œå¹¶è¡Œåˆ†æ...")
            parallel_result = await parallel_analysis.run_async(session)

            # Create sequential evaluation stage
            print("ğŸ“Š åˆ›å»ºè¯„ä¼°é˜¶æ®µ...")
            sequential_evaluation = self.create_sequential_evaluation(request, {})

            # Run sequential evaluation
            print("âœ… è¿è¡Œè¯„ä¼°å’ŒæŠ¥å‘Šç”Ÿæˆ...")
            final_result = await sequential_evaluation.run_async(session)

            # Create successful result
            execution_time = time.time() - start_time

            return PipelineResult(
                success=True,
                state=AnalysisState(
                    request=request,
                    phase="completed",
                    progress=1.0
                ),
                execution_time=execution_time
            )

        except Exception as e:
            execution_time = time.time() - start_time
            return PipelineResult(
                success=False,
                error=str(e),
                execution_time=execution_time
            )


def create_analysis_pipeline(settings: Optional[Settings] = None) -> AnalysisPipeline:
    """
    Factory function to create an analysis pipeline.

    Args:
        settings: Optional settings object

    Returns:
        AnalysisPipeline instance
    """
    return AnalysisPipeline(settings)
'''

    pipeline_file = os.path.join(src_path, 'workflows', 'analysis_pipeline.py')
    backup_file = pipeline_file + '.backup'

    try:
        # å¤‡ä»½åŸæ–‡ä»¶
        if os.path.exists(pipeline_file):
            with open(pipeline_file, 'r', encoding='utf-8') as f:
                original_content = f.read()
            with open(backup_file, 'w', encoding='utf-8') as f:
                f.write(original_content)
            print(f"âœ… åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_file}")

        # å†™å…¥ä¿®å¤ç‰ˆæœ¬
        with open(pipeline_file, 'w', encoding='utf-8') as f:
            f.write(fixed_content)
        print(f"âœ… ä¿®å¤ç‰ˆæœ¬å·²å†™å…¥: {pipeline_file}")

        return True

    except Exception as e:
        print(f"âŒ å†™å…¥ä¿®å¤ç‰ˆæœ¬å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¿®å¤agentså¯¼å…¥é—®é¢˜")
    print("=" * 50)

    # æµ‹è¯•å½“å‰å¯¼å…¥
    if test_analysis_pipeline_import():
        print("\nâœ… å¯¼å…¥æµ‹è¯•é€šè¿‡ï¼Œæ— éœ€ä¿®å¤")
        return 0

    # åˆ›å»ºä¿®å¤ç‰ˆæœ¬
    if create_fixed_analysis_pipeline():
        print("\nğŸ”§ ä¿®å¤ç‰ˆæœ¬åˆ›å»ºå®Œæˆ")

        # å†æ¬¡æµ‹è¯•
        print("\nğŸ§ª æµ‹è¯•ä¿®å¤åçš„å¯¼å…¥...")
        if test_analysis_pipeline_import():
            print("âœ… ä¿®å¤æˆåŠŸï¼")
            return 0
        else:
            print("âŒ ä¿®å¤å¤±è´¥ï¼Œé—®é¢˜ä»ç„¶å­˜åœ¨")
            return 1
    else:
        print("âŒ ä¿®å¤ç‰ˆæœ¬åˆ›å»ºå¤±è´¥")
        return 1

if __name__ == "__main__":
    sys.exit(main())